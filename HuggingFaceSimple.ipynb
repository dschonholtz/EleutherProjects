{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172078b2-4499-4eea-98f4-2450a783adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines\n",
    "from transformers import pipeline\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f3c7ab-d045-415f-9ceb-6c206698300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'EleutherAI has developed two key technologies to aid the search engine optimization process:\\n\\nAn Efficient Search Index, and\\n\\nAn Efficient Metadata\\n\\nA Search Index\\n\\nAll Search Engines will use a search index to find'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B')\n",
    "generator(\"EleutherAI has\", do_sample=True, min_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54bf09f6-8230-4f4d-8972-95fb94407675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What the fuck did you just fucking say about me, you little bitch? I\\'ll have you know I graduated top of my class in the Navy Seals. I\\'m a fucking hero. You\\'re nothing but a fucking whore.\"\\n\\n\"You'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Doug just got an oculus go and is going to\", do_sample=True, min_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f491fdb-f682-4b97-97c4-feaf04418abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21788 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
    "\n",
    "\n",
    "data_path = '/media/douglas/Seagate Portable Drive/the-eye.eu/public/AI/pile/train/00.jsonl'\n",
    "result_path = '/media/douglas/Seagate Portable Drive/the-eye.eu/public/AI/pile/train/00_temp1_50_in_50out.jsonl'\n",
    "result_07_temp = '/media/douglas/Seagate Portable Drive/the-eye.eu/public/AI/pile/train/00_temp07_50_in_50out.jsonl'\n",
    "result_04_temp = '/media/douglas/Seagate Portable Drive/the-eye.eu/public/AI/pile/train/00_temp04_50_in_50out.jsonl'\n",
    "with jsonlines.open(data_path) as reader:\n",
    "    count = 0\n",
    "    for obj in reader:\n",
    "        count += 1\n",
    "        if count == 0 or count % 25000 == 0:\n",
    "            tokens = tokenizer(obj['text'])\n",
    "            tokens_in = tokenizer.decode(tokens[\"input_ids\"][0:50])\n",
    "            expected_out = tokenizer.decode(tokens[\"input_ids\"][50:100])\n",
    "\n",
    "            output = generator(tokens_in, do_sample=True, min_length=100, max_length=300)\n",
    "\n",
    "            result = {\n",
    "                'prompt': tokens_in,\n",
    "                'expected': expected_out,\n",
    "                'actual': output[0]['generated_text'][len(tokens_in):]\n",
    "\n",
    "            }\n",
    "            \n",
    "            with jsonlines.open(result_path, mode='a') as writer:\n",
    "                writer.write(result)\n",
    "            \n",
    "            output = generator(tokens_in, do_sample=True, temperature=.7, min_length=100, max_length=300)\n",
    "\n",
    "            result = {\n",
    "                'prompt': tokens_in,\n",
    "                'expected': expected_out,\n",
    "                'actual': output[0]['generated_text'][len(tokens_in):]\n",
    "            }\n",
    "            with jsonlines.open(result_07_temp, mode='a') as writer:\n",
    "                writer.write(result)\n",
    "                \n",
    "            output = generator(tokens_in, do_sample=True, temperature=.4, min_length=100, max_length=300)\n",
    "\n",
    "            result = {\n",
    "                'prompt': tokens_in,\n",
    "                'expected': expected_out,\n",
    "                'actual': output[0]['generated_text'][len(tokens_in):]\n",
    "            }\n",
    "            with jsonlines.open(result_04_temp, mode='a') as writer:\n",
    "                writer.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef6c07-0e7b-4af3-bab0-a2062aa0236a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
